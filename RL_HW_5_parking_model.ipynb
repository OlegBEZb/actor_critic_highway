{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"parking_model_based.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-oVNY_KTw6R"
      },
      "source": [
        "## Our challenge: Automated Parking System\n",
        "\n",
        "We consider the **parking-v0** task of the [highway-env](https://github.com/eleurent/highway-env) environment. It is a **goal-conditioned continuous control** task where an agent **drives a car** by controlling the gaz pedal and steering angle and must **park in a given location** with the appropriate heading.\n",
        "\n",
        "This MDP has several properties wich justifies using model-based methods:\n",
        "* The policy/value is highly dependent on the goal which adds a significant level of complexity to a model-free learning process, whereas the dynamics are completely independent of the goal and hence can be simpler to learn.\n",
        "* In the context of an industrial application, we can reasonably expect for safety concerns that the planned trajectory is required to be known in advance, before execution.\n",
        "\n",
        "###  Warming up\n",
        "We start with a few useful installs and imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzMSuJEOfviP",
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Install environment and visualization dependencies \n",
        "!pip install highway-env\n",
        "!pip install gym pyvirtualdisplay\n",
        "!apt-get update\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -y\n",
        "\n",
        "# Environment\n",
        "import gym\n",
        "import highway_env\n",
        "\n",
        "# Models and computation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm.notebook import trange\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "from gym.wrappers import Monitor\n",
        "import base64\n",
        "\n",
        "# IO\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Bu_Pqop0E7"
      },
      "source": [
        "We also define a simple helper function for visualization of episodes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so7yH4ucyB-3"
      },
      "source": [
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video(path):\n",
        "    html = []\n",
        "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay \n",
        "                      loop controls style=\"height: 400px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFtBY6JSqPFa"
      },
      "source": [
        "### Let's try it!\n",
        "\n",
        "Make the environment, and run an episode with random actions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKZt9Cb1rJ6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "2e4c66b8-41ee-44b9-95c1-616eef0b2562"
      },
      "source": [
        "env = gym.make(\"parking-v0\")\n",
        "env = Monitor(env, './video', force=True, video_callable=lambda episode: True)\n",
        "env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, done, info = env.step(action)\n",
        "env.close()\n",
        "show_video('./video')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"video/openaigym.video.6.2313.video000000.mp4\" autoplay \n",
              "                      loop controls style=\"height: 400px;\">\n",
              "                      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                 </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewG5f_essAS0"
      },
      "source": [
        "The environment is a `GoalEnv`, which means the agent receives a dictionary containing both the current `observation` and the `desired_goal` that conditions its policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIC98mGhr7v6"
      },
      "source": [
        "print(\"Observation format:\", obs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjYvyigH1Rv4"
      },
      "source": [
        "env.observation_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IQN0M8Ryto3"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voagCILztJ3J"
      },
      "source": [
        "There is also an `achieved_goal` that won't be useful here (it only serves when the state and goal spaces are different, as a projection from the observation to the goal space)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCXb9ca3n7qi"
      },
      "source": [
        "# Modeling\n",
        "Try with both buffers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZOJwxKLlx9G"
      },
      "source": [
        "!pip install stable-baselines3\n",
        "!pip install sb3-contrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fthS9HdtxOHs"
      },
      "source": [
        "## Buffers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGNZPCwFifLm"
      },
      "source": [
        "### Dict replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8vdCmJYiMT0"
      },
      "source": [
        "from typing import Optional\n",
        "from stable_baselines3.common.vec_env import VecEnv, VecNormalize\n",
        "\n",
        "from actor_critic_highway.dict_buffer import DictReplayBufferBase, DictReplayBufferSamples\n",
        "\n",
        "\n",
        "class DictReplayBuffer(DictReplayBufferBase):\n",
        "\n",
        "    def sample(self, batch_size: int, env: Optional[VecNormalize] = None) -> DictReplayBufferSamples:\n",
        "        \"\"\"\n",
        "        Sample elements from the replay buffer.\n",
        "        :param batch_size: Number of element to sample\n",
        "        :param env: associated gym VecEnv\n",
        "            to normalize the observations/rewards when sampling\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        ### YOUR CODE HERE ###\n",
        "        batch_inds = []  # <-- Get random indexes\n",
        "        ######################\n",
        "        return self._get_samples(batch_inds, env=env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XV9KrXTil7P"
      },
      "source": [
        "### HER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WVM6_W-hb__"
      },
      "source": [
        "from actor_critic_highway.her_buffers import HerReplayBufferBase\n",
        "\n",
        "\n",
        "# For convenience\n",
        "# that way, we can use string to select a strategy\n",
        "GOAL_STRATEGY_MAPPING = {\n",
        "    \"future\": 0,\n",
        "    \"final\": 1,\n",
        "    \"episode\": 2,\n",
        "}\n",
        "\n",
        "\n",
        "class HerReplayBuffer(HerReplayBufferBase):\n",
        "\n",
        "    def sample(\n",
        "            self,\n",
        "            batch_size: int,\n",
        "            env: Optional[VecNormalize],\n",
        "    ) -> DictReplayBufferSamples:\n",
        "        \"\"\"\n",
        "        Sample function for online sampling of HER transition,\n",
        "        this replaces the \"regular\" replay buffer ``sample()``\n",
        "        method in the ``train()`` function.\n",
        "        :param batch_size: Number of element to sample\n",
        "        :param env: Associated gym VecEnv\n",
        "            to normalize the observations/rewards when sampling\n",
        "        :return: Samples.\n",
        "        \"\"\"\n",
        "        # TODO: for student\n",
        "        # If online sampling, use self._sample_transitions();\n",
        "        # if offline, use self.replay_buffer.sample():\n",
        "        return None\n",
        "\n",
        "    def _sample_her_transitions(self) -> None:\n",
        "        \"\"\"\n",
        "        Sample additional goals and store new transitions in replay buffer\n",
        "        when using offline sampling.\n",
        "        \"\"\"\n",
        "\n",
        "        # Sample goals to create virtual transitions for the last episode.\n",
        "        # TODO: for student\n",
        "        observations, next_observations, actions, rewards = self._sample_offline(n_sampled_goal=self.n_sampled_goal)\n",
        "\n",
        "        if len(observations) > 0:\n",
        "            for i in range(len(observations[\"observation\"])):\n",
        "              ### YOUR CODE HERE ###\n",
        "              # Store virtual transitions in the replay buffer\n",
        "              # use self.replay_buffer.add() method:\n",
        "              pass\n",
        "              ######################\n",
        "              \n",
        "\n",
        "    def sample_goals(\n",
        "            self,\n",
        "            episode_indices: np.ndarray,\n",
        "            her_indices: np.ndarray,\n",
        "            transitions_indices: np.ndarray,\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Sample goals based on goal_selection_strategy.\n",
        "        This is a vectorized (fast) version.\n",
        "        :param episode_indices: Episode indices to use.\n",
        "        :param her_indices: HER indices.\n",
        "        :param transitions_indices: Transition indices to use.\n",
        "        :return: Return sampled goals.\n",
        "        \"\"\"\n",
        "        her_episode_indices = episode_indices[her_indices]\n",
        "\n",
        "        if self.goal_selection_strategy == 1:\n",
        "            ### YOUR CODE HERE ###\n",
        "            transitions_indices = []  # <-- Get index of the final state of the current episode\n",
        "            ######################\n",
        "\n",
        "        elif self.goal_selection_strategy == 0:\n",
        "            ### YOUR CODE HERE ###\n",
        "            transitions_indices = []  # <-- Get index of a random state happened after the current one\n",
        "            ######################\n",
        "\n",
        "        elif self.goal_selection_strategy == 2:\n",
        "            ### YOUR CODE HERE ###\n",
        "            transitions_indices = []  # <-- Get random index of the current episode\n",
        "            ######################\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Strategy {self.goal_selection_strategy} for sampling goals not supported!\")\n",
        "\n",
        "        return self._buffer[\"achieved_goal\"][her_episode_indices, transitions_indices]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWdgvi_Qq92e"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNxjYAVHrRQx"
      },
      "source": [
        "### TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9sySpWarS3A"
      },
      "source": [
        "from actor_critic_highway.td3 import TD3_base\n",
        "from stable_baselines3.common.utils import polyak_update\n",
        "from stable_baselines3.common.vec_env import VecEnv\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "class TD3(TD3_base):\n",
        "\n",
        "      def train(self, gradient_steps: int, batch_size: int = 100) -> None:\n",
        "        # Switch to train mode (this affects batch norm / dropout)\n",
        "        self.policy.set_training_mode(True)\n",
        "\n",
        "        # Update learning rate according to lr schedule\n",
        "        self._update_learning_rate([self.actor.optimizer, self.critic.optimizer])\n",
        "\n",
        "        actor_losses, critic_losses = [], []\n",
        "\n",
        "        for _ in range(gradient_steps):\n",
        "\n",
        "            self._n_updates += 1\n",
        "            # Sample replay buffer\n",
        "            replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)\n",
        "\n",
        "            with th.no_grad():\n",
        "                # Select action according to policy and add clipped noise:\n",
        "\n",
        "                # 1. Generate noise with shape == replay_data.actions.shape\n",
        "                # 2. Clip noise with a constant self.target_noise_clip\n",
        "                # 3. Add noise to the action tensor:\n",
        "                # YOUR CODE HERE:\n",
        "                #################\n",
        "                noise = None\n",
        "                next_actions = None\n",
        "\n",
        "                # 1. Get next Q values from critic network (min over all critics targets)\n",
        "                # 2. Update Q values for target network using specific formula\n",
        "                # YOUR CODE HERE:\n",
        "                #################\n",
        "                pass  # remove after completing gaps\n",
        "\n",
        "            # Get current Q-values estimates for each critic network\n",
        "            current_q_values = self.critic(replay_data.observations, replay_data.actions)\n",
        "\n",
        "            # 1. Compute MSE loss between current and target Q values:\n",
        "            # YOUR CODE HERE:\n",
        "            #################\n",
        "            critic_loss = None\n",
        "\n",
        "            critic_losses.append(critic_loss.item())\n",
        "\n",
        "            # Optimize the critics\n",
        "            self.critic.optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            self.critic.optimizer.step()\n",
        "\n",
        "            # Delayed policy updates\n",
        "            if self._n_updates % self.policy_delay == 0:\n",
        "\n",
        "                # 1. Compute actor loss using critic network:\n",
        "                # YOUR CODE HERE:\n",
        "                #################\n",
        "                actor_loss: th.Tensor = 0  # Replace it\n",
        "\n",
        "                # Optimize the actor\n",
        "                self.actor.optimizer.zero_grad()\n",
        "                actor_loss.backward()\n",
        "                self.actor.optimizer.step()\n",
        "\n",
        "                polyak_update(self.critic.parameters(), self.critic_target.parameters(), self.tau)\n",
        "                polyak_update(self.actor.parameters(), self.actor_target.parameters(), self.tau)\n",
        "\n",
        "        self.logger.record(\"train/n_updates\", self._n_updates, exclude=\"tensorboard\")\n",
        "        if len(actor_losses) > 0:\n",
        "            self.logger.record(\"train/actor_loss\", np.mean(actor_losses))\n",
        "        self.logger.record(\"train/critic_loss\", np.mean(critic_losses))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK4YTm-prWpm"
      },
      "source": [
        "### DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enDjGBJdrqMp"
      },
      "source": [
        "from typing import Any, Dict, Optional, Tuple, Type, Union\n",
        "\n",
        "from stable_baselines3.td3.policies import TD3Policy\n",
        "import torch as th\n",
        "\n",
        "from stable_baselines3.common.noise import ActionNoise\n",
        "from stable_baselines3.common.type_aliases import GymEnv, MaybeCallback, Schedule\n",
        "\n",
        "\n",
        "class DDPG(TD3):\n",
        "    \"\"\"\n",
        "    Deep Deterministic Policy Gradient (DDPG).\n",
        "    Deterministic Policy Gradient: http://proceedings.mlr.press/v32/silver14.pdf\n",
        "    DDPG Paper: https://arxiv.org/abs/1509.02971\n",
        "    Introduction to DDPG: https://spinningup.openai.com/en/latest/algorithms/ddpg.html\n",
        "    Note: we treat DDPG as a special case of its successor TD3.\n",
        "    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
        "    :param env: The environment to learn from (if registered in Gym, can be str)\n",
        "    :param learning_rate: learning rate for adam optimizer,\n",
        "        the same learning rate will be used for all networks (Q-Values, Actor and Value function)\n",
        "        it can be a function of the current progress remaining (from 1 to 0)\n",
        "    :param buffer_size: size of the replay buffer\n",
        "    :param learning_starts: how many steps of the model to collect transitions for before learning starts\n",
        "    :param batch_size: Minibatch size for each gradient update\n",
        "    :param tau: the soft update coefficient (\"Polyak update\", between 0 and 1)\n",
        "    :param gamma: the discount factor\n",
        "    :param train_freq: Update the model every ``train_freq`` steps. Alternatively pass a tuple of frequency and unit\n",
        "        like ``(5, \"step\")`` or ``(2, \"episode\")``.\n",
        "    :param gradient_steps: How many gradient steps to do after each rollout (see ``train_freq``)\n",
        "        Set to ``-1`` means to do as many gradient steps as steps done in the environment\n",
        "        during the rollout.\n",
        "    :param action_noise: the action noise type (None by default), this can help\n",
        "        for hard exploration problem. Cf common.noise for the different action noise type.\n",
        "    :param replay_buffer_class: Replay buffer class to use (for instance ``HerReplayBuffer``).\n",
        "        If ``None``, it will be automatically selected.\n",
        "    :param replay_buffer_kwargs: Keyword arguments to pass to the replay buffer on creation.\n",
        "    :param optimize_memory_usage: Enable a memory efficient variant of the replay buffer\n",
        "        at a cost of more complexity.\n",
        "        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n",
        "    :param create_eval_env: Whether to create a second environment that will be\n",
        "        used for evaluating the agent periodically. (Only available when passing string for the environment)\n",
        "    :param policy_kwargs: additional arguments to be passed to the policy on creation\n",
        "    :param verbose: the verbosity level: 0 no output, 1 info, 2 debug\n",
        "    :param seed: Seed for the pseudo random generators\n",
        "    :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
        "        Setting it to auto, the code will be run on the GPU if possible.\n",
        "    :param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        policy: Union[str, Type[TD3Policy]],\n",
        "        env: Union[GymEnv, str],\n",
        "        learning_rate: Union[float, Schedule] = 1e-3,\n",
        "        buffer_size: int = 1000000,  # 1e6\n",
        "        learning_starts: int = 100,\n",
        "        batch_size: int = 100,\n",
        "        tau: float = 0.005,\n",
        "        gamma: float = 0.99,\n",
        "        train_freq: Union[int, Tuple[int, str]] = (1, \"episode\"),\n",
        "        gradient_steps: int = -1,\n",
        "        action_noise: Optional[ActionNoise] = None,\n",
        "        replay_buffer_class: Optional[DictReplayBufferBase] = None,\n",
        "        replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        optimize_memory_usage: bool = False,\n",
        "        tensorboard_log: Optional[str] = None,\n",
        "        create_eval_env: bool = False,\n",
        "        policy_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        verbose: int = 0,\n",
        "        seed: Optional[int] = None,\n",
        "        device: Union[th.device, str] = \"auto\",\n",
        "        _init_setup_model: bool = True,\n",
        "    ):\n",
        "\n",
        "        super(DDPG, self).__init__(\n",
        "            policy=policy,\n",
        "            env=env,\n",
        "            learning_rate=learning_rate,\n",
        "            buffer_size=buffer_size,\n",
        "            learning_starts=learning_starts,\n",
        "            batch_size=batch_size,\n",
        "            tau=tau,\n",
        "            gamma=gamma,\n",
        "            train_freq=train_freq,\n",
        "            gradient_steps=gradient_steps,\n",
        "            action_noise=action_noise,\n",
        "            replay_buffer_class=replay_buffer_class,\n",
        "            replay_buffer_kwargs=replay_buffer_kwargs,\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            tensorboard_log=tensorboard_log,\n",
        "            verbose=verbose,\n",
        "            device=device,\n",
        "            create_eval_env=create_eval_env,\n",
        "            seed=seed,\n",
        "            optimize_memory_usage=optimize_memory_usage,\n",
        "            # Remove all tricks from TD3 to obtain DDPG:\n",
        "            # we still need to specify target_policy_noise > 0 to avoid errors\n",
        "            policy_delay=1,\n",
        "            target_noise_clip=0.0,\n",
        "            target_policy_noise=0.1,\n",
        "            _init_setup_model=False,\n",
        "        )\n",
        "\n",
        "        # Use only one critic\n",
        "        if \"n_critics\" not in self.policy_kwargs:\n",
        "            self.policy_kwargs[\"n_critics\"] = 1\n",
        "\n",
        "        if _init_setup_model:\n",
        "            self._setup_model()\n",
        "\n",
        "    def learn(\n",
        "        self,\n",
        "        total_timesteps: int,\n",
        "        callback: MaybeCallback = None,\n",
        "        log_interval: int = 4,\n",
        "        eval_env: Optional[GymEnv] = None,\n",
        "        eval_freq: int = -1,\n",
        "        n_eval_episodes: int = 5,\n",
        "        tb_log_name: str = \"DDPG\",\n",
        "        eval_log_path: Optional[str] = None,\n",
        "        reset_num_timesteps: bool = True,\n",
        "    ) :\n",
        "\n",
        "        return super(DDPG, self).learn(\n",
        "            total_timesteps=total_timesteps,\n",
        "            callback=callback,\n",
        "            log_interval=log_interval,\n",
        "            eval_env=eval_env,\n",
        "            eval_freq=eval_freq,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            tb_log_name=tb_log_name,\n",
        "            eval_log_path=eval_log_path,\n",
        "            reset_num_timesteps=reset_num_timesteps,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTEdH3tPh-Ts"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcv-D0FZn8-6",
        "outputId": "a8ff0bfb-84d2-4650-d35a-f5b51b61a0c2"
      },
      "source": [
        "# Agent\n",
        "from stable_baselines3.td3.policies import MultiInputPolicy\n",
        "from actor_critic_highway.dict_buffer import DictReplayBuffer\n",
        "from actor_critic_highway.her_buffers import HerReplayBuffer\n",
        "\n",
        "\n",
        "env = gym.make(\"parking-v0\")\n",
        "her_kwargs = dict(\n",
        "    n_sampled_goal=4, \n",
        "    goal_selection_strategy='future', \n",
        "    online_sampling=True,\n",
        "     max_episode_length=100\n",
        "     )\n",
        "\n",
        "model = TD3(policy=MultiInputPolicy,\n",
        "             env=env,\n",
        "             verbose=1,\n",
        "            #  replay_buffer_class=DictReplayBuffer,\n",
        "             replay_buffer_class=HerReplayBuffer,\n",
        "             replay_buffer_kwargs=her_kwargs,\n",
        "            policy_kwargs=dict()\n",
        "             )\n",
        "\n",
        "model.learn(int(1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 50       |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total timesteps | 400      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.505    |\n",
            "|    critic_loss     | 0.00998  |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 200      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -86.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 44       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.87     |\n",
            "|    critic_loss     | 0.0689   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 600      |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TD3 at 0x7f2d2191fad0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZOEczaE6VJR",
        "outputId": "064846fb-7f58-459f-81e2-6ad99df802bf"
      },
      "source": [
        "model = DDPG(policy=MultiInputPolicy,\n",
        "             env=env,\n",
        "             verbose=1,\n",
        "             replay_buffer_class=DictReplayBuffer,\n",
        "            #  replay_buffer_class=HerReplayBuffer,\n",
        "            #  replay_buffer_kwargs=her_kwargs,\n",
        "            policy_kwargs=dict()\n",
        "             )\n",
        "\n",
        "model.learn(int(5e4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "<class '__main__.DictReplayBuffer'>\n",
            "<__main__.DictReplayBuffer object at 0x7f1a174d8b50>\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -79.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 50       |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total timesteps | 400      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.74     |\n",
            "|    critic_loss     | 0.0931   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 200      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -65.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 43       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.4      |\n",
            "|    critic_loss     | 0.111    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 600      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -63.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 41       |\n",
            "|    time_elapsed    | 28       |\n",
            "|    total timesteps | 1200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.01     |\n",
            "|    critic_loss     | 0.132    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -65.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 40       |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.99     |\n",
            "|    critic_loss     | 0.242    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -60.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 50       |\n",
            "|    total timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.63     |\n",
            "|    critic_loss     | 0.35     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.98     |\n",
            "|    critic_loss     | 0.312    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2200     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total timesteps | 2800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.51     |\n",
            "|    critic_loss     | 0.336    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.93     |\n",
            "|    critic_loss     | 0.389    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 92       |\n",
            "|    total timesteps | 3600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.39     |\n",
            "|    critic_loss     | 0.404    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 39       |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.76     |\n",
            "|    critic_loss     | 0.488    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 113      |\n",
            "|    total timesteps | 4400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.19     |\n",
            "|    critic_loss     | 0.504    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4200     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 123      |\n",
            "|    total timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.63     |\n",
            "|    critic_loss     | 0.471    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 133      |\n",
            "|    total timesteps | 5200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.92     |\n",
            "|    critic_loss     | 0.559    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 144      |\n",
            "|    total timesteps | 5600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.21     |\n",
            "|    critic_loss     | 0.539    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 154      |\n",
            "|    total timesteps | 6000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.46     |\n",
            "|    critic_loss     | 0.571    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 165      |\n",
            "|    total timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.73     |\n",
            "|    critic_loss     | 0.673    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6200     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 175      |\n",
            "|    total timesteps | 6800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 8.94     |\n",
            "|    critic_loss     | 0.664    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total timesteps | 7200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.13     |\n",
            "|    critic_loss     | 0.751    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 196      |\n",
            "|    total timesteps | 7600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.46     |\n",
            "|    critic_loss     | 0.808    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 207      |\n",
            "|    total timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.65     |\n",
            "|    critic_loss     | 0.814    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 217      |\n",
            "|    total timesteps | 8400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.74     |\n",
            "|    critic_loss     | 0.799    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8200     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 228      |\n",
            "|    total timesteps | 8800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.76     |\n",
            "|    critic_loss     | 0.752    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8600     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 238      |\n",
            "|    total timesteps | 9200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.1     |\n",
            "|    critic_loss     | 0.751    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 249      |\n",
            "|    total timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.2     |\n",
            "|    critic_loss     | 0.791    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9400     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 260      |\n",
            "|    total timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.3     |\n",
            "|    critic_loss     | 0.921    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9800     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 270      |\n",
            "|    total timesteps | 10400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.6     |\n",
            "|    critic_loss     | 0.901    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 10200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 281      |\n",
            "|    total timesteps | 10800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.7     |\n",
            "|    critic_loss     | 0.971    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 10600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 291      |\n",
            "|    total timesteps | 11200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 10.9     |\n",
            "|    critic_loss     | 0.999    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 11000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 302      |\n",
            "|    total timesteps | 11600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11       |\n",
            "|    critic_loss     | 0.982    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 11400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 312      |\n",
            "|    total timesteps | 12000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.2     |\n",
            "|    critic_loss     | 0.94     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 11800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 323      |\n",
            "|    total timesteps | 12400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 0.968    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 12200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 333      |\n",
            "|    total timesteps | 12800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.34     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 12600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 344      |\n",
            "|    total timesteps | 13200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.6     |\n",
            "|    critic_loss     | 1.25     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 13000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 354      |\n",
            "|    total timesteps | 13600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.12     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 13400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 365      |\n",
            "|    total timesteps | 14000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.23     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 13800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 375      |\n",
            "|    total timesteps | 14400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 0.984    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 14200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 386      |\n",
            "|    total timesteps | 14800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.05     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 14600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 397      |\n",
            "|    total timesteps | 15200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.6     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 15000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 407      |\n",
            "|    total timesteps | 15600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.24     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 15400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 418      |\n",
            "|    total timesteps | 16000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.26     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 15800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 428      |\n",
            "|    total timesteps | 16400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.07     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 16200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 439      |\n",
            "|    total timesteps | 16800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.13     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 16600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 450      |\n",
            "|    total timesteps | 17200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 17000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 460      |\n",
            "|    total timesteps | 17600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.19     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 17400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 471      |\n",
            "|    total timesteps | 18000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.34     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 17800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 482      |\n",
            "|    total timesteps | 18400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.4     |\n",
            "|    critic_loss     | 1.1      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 18200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 492      |\n",
            "|    total timesteps | 18800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.5     |\n",
            "|    critic_loss     | 1.17     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 18600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 503      |\n",
            "|    total timesteps | 19200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.6     |\n",
            "|    critic_loss     | 1.44     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 514      |\n",
            "|    total timesteps | 19600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.8     |\n",
            "|    critic_loss     | 1.1      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 524      |\n",
            "|    total timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.9     |\n",
            "|    critic_loss     | 1.24     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 19800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 535      |\n",
            "|    total timesteps | 20400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.9     |\n",
            "|    critic_loss     | 1.21     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 208      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 545      |\n",
            "|    total timesteps | 20800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.9     |\n",
            "|    critic_loss     | 1.4      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 556      |\n",
            "|    total timesteps | 21200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.1     |\n",
            "|    critic_loss     | 1.08     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 21000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 216      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 567      |\n",
            "|    total timesteps | 21600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12       |\n",
            "|    critic_loss     | 1.61     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 21400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 577      |\n",
            "|    total timesteps | 22000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.1     |\n",
            "|    critic_loss     | 1.13     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 21800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 588      |\n",
            "|    total timesteps | 22400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.1     |\n",
            "|    critic_loss     | 1.19     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 22200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 228      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 598      |\n",
            "|    total timesteps | 22800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.3     |\n",
            "|    critic_loss     | 1.18     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 22600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 609      |\n",
            "|    total timesteps | 23200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.3     |\n",
            "|    critic_loss     | 1.42     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 236      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 619      |\n",
            "|    total timesteps | 23600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.5     |\n",
            "|    critic_loss     | 1.18     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 630      |\n",
            "|    total timesteps | 24000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.5     |\n",
            "|    critic_loss     | 1.35     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 23800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 641      |\n",
            "|    total timesteps | 24400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.6     |\n",
            "|    critic_loss     | 1.1      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 24200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 248      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 651      |\n",
            "|    total timesteps | 24800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.6     |\n",
            "|    critic_loss     | 1.42     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 24600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 662      |\n",
            "|    total timesteps | 25200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.6     |\n",
            "|    critic_loss     | 1.42     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 25000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 256      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 672      |\n",
            "|    total timesteps | 25600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.43     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 25400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 683      |\n",
            "|    total timesteps | 26000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.72     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 25800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 264      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 693      |\n",
            "|    total timesteps | 26400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 26200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 268      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 704      |\n",
            "|    total timesteps | 26800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.2      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 26600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 272      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 714      |\n",
            "|    total timesteps | 27200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.25     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 276      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 725      |\n",
            "|    total timesteps | 27600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.61     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 735      |\n",
            "|    total timesteps | 28000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.5      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 284      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 746      |\n",
            "|    total timesteps | 28400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.65     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 28200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 288      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 757      |\n",
            "|    total timesteps | 28800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.4      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 28600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 292      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 767      |\n",
            "|    total timesteps | 29200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.31     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 296      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 778      |\n",
            "|    total timesteps | 29600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.14     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 789      |\n",
            "|    total timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.27     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 29800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 304      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 799      |\n",
            "|    total timesteps | 30400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.2      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 30200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 308      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 810      |\n",
            "|    total timesteps | 30800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.23     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 30600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 312      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 820      |\n",
            "|    total timesteps | 31200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.15     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 316      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 831      |\n",
            "|    total timesteps | 31600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.47     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 841      |\n",
            "|    total timesteps | 32000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.48     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 324      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 851      |\n",
            "|    total timesteps | 32400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13       |\n",
            "|    critic_loss     | 1.28     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 328      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 862      |\n",
            "|    total timesteps | 32800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.52     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 32600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 332      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 872      |\n",
            "|    total timesteps | 33200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.55     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 33000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 336      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 883      |\n",
            "|    total timesteps | 33600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.32     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 33400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 893      |\n",
            "|    total timesteps | 34000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.28     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 33800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 344      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 904      |\n",
            "|    total timesteps | 34400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.54     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 34200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 348      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 914      |\n",
            "|    total timesteps | 34800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.38     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 34600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 352      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 925      |\n",
            "|    total timesteps | 35200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.62     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 35000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 356      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 935      |\n",
            "|    total timesteps | 35600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.62     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 35400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 945      |\n",
            "|    total timesteps | 36000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.58     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 35800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 364      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 956      |\n",
            "|    total timesteps | 36400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.59     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 36200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 368      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 966      |\n",
            "|    total timesteps | 36800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.58     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 36600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 372      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 977      |\n",
            "|    total timesteps | 37200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.55     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 37000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 376      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 987      |\n",
            "|    total timesteps | 37600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.55     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 37400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 997      |\n",
            "|    total timesteps | 38000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.69     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 37800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 384      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1008     |\n",
            "|    total timesteps | 38400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.51     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 38200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -58.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 388      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1019     |\n",
            "|    total timesteps | 38800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.53     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 38600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.2    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 392      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1029     |\n",
            "|    total timesteps | 39200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.49     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 39000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.9    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 396      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1040     |\n",
            "|    total timesteps | 39600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.66     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 39400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1050     |\n",
            "|    total timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.79     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 39800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 404      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1060     |\n",
            "|    total timesteps | 40400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.54     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 408      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1071     |\n",
            "|    total timesteps | 40800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.54     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 412      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1081     |\n",
            "|    total timesteps | 41200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.57     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.5    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 416      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1092     |\n",
            "|    total timesteps | 41600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.38     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1102     |\n",
            "|    total timesteps | 42000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.3     |\n",
            "|    critic_loss     | 1.72     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 41800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1112     |\n",
            "|    total timesteps | 42400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.39     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 428      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1122     |\n",
            "|    total timesteps | 42800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.55     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 432      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1133     |\n",
            "|    total timesteps | 43200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.4     |\n",
            "|    critic_loss     | 1.53     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -60      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 436      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1143     |\n",
            "|    total timesteps | 43600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.76     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1153     |\n",
            "|    total timesteps | 44000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.55     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 444      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1164     |\n",
            "|    total timesteps | 44400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.2     |\n",
            "|    critic_loss     | 1.47     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 448      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1174     |\n",
            "|    total timesteps | 44800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.6      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 44600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.4    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 452      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1184     |\n",
            "|    total timesteps | 45200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13       |\n",
            "|    critic_loss     | 1.29     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -59.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 456      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1195     |\n",
            "|    total timesteps | 45600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13.1     |\n",
            "|    critic_loss     | 1.49     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -57.8    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1205     |\n",
            "|    total timesteps | 46000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13       |\n",
            "|    critic_loss     | 1.41     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 45800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -56.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1216     |\n",
            "|    total timesteps | 46400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13       |\n",
            "|    critic_loss     | 1.31     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 468      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1226     |\n",
            "|    total timesteps | 46800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.22     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 46600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.6    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 472      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1237     |\n",
            "|    total timesteps | 47200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.9     |\n",
            "|    critic_loss     | 1.69     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55.1    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 476      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1247     |\n",
            "|    total timesteps | 47600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.51     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47400    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -55      |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1257     |\n",
            "|    total timesteps | 48000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.18     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 47800    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.7    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 484      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1268     |\n",
            "|    total timesteps | 48400    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.35     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48200    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 488      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1278     |\n",
            "|    total timesteps | 48800    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.39     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 48600    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 100      |\n",
            "|    ep_rew_mean     | -54.3    |\n",
            "|    success rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 492      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1289     |\n",
            "|    total timesteps | 49200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.35     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.1     |\n",
            "|    ep_rew_mean     | -53.1    |\n",
            "|    success rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 496      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1297     |\n",
            "|    total timesteps | 49513    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.7     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49313    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.1     |\n",
            "|    ep_rew_mean     | -53.5    |\n",
            "|    success rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 1307     |\n",
            "|    total timesteps | 49913    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 12.8     |\n",
            "|    critic_loss     | 1.33     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 49713    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.DDPG at 0x7f1a18df5f90>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpNthoZNpD-h"
      },
      "source": [
        "# Test the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgIbtcHv2MoY"
      },
      "source": [
        "import os\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rewSb5t3pCOD"
      },
      "source": [
        "env = gym.make(\"parking-v0\")\n",
        "env = Monitor(env, './video', force=True, video_callable=lambda episode: True)\n",
        "for episode in trange(3, desc=\"Test episodes\"):\n",
        "    obs, done = env.reset(), False\n",
        "    env.unwrapped.automatic_rendering_callback = env.video_recorder.capture_frame\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        \n",
        "env.close()\n",
        "show_video('./video')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}